#  Requests库入门

### Unit 1：Requests库方法

- Requests库的七个主要方法

  | 方法                 | 说明                              |
  | ------------------ | ------------------------------- |
  | requests.request() | 构造请求，是支撑以下方法的基础方法               |
  | requests.get()     | 获取HTML网页的主要方法，对应于HTTP的GET       |
  | requests.head()    | 获取HTML网页头信息的方法，对应于HTTP的HEAD     |
  | requests.post()    | 向HTML网页提交POST请求的方法，对应于HTTP的POST |
  | requests.put()     | 向HTML网页提交PUT请求的方法，对应于HTTP的PUT   |
  | requests.patch()   | 向HTML网页提交局部修改请求，对应于HTTP的PATCH   |
  | requests.delete()  | 向HTML网页提交删除请求，对应于HTTP的DELETE    |

- get方法

   -  获得一个网页最简单的方法:

      `r = requests.get(url)`

      Request: 构造一个向server请求resource的Request对象。

      Response: 返回一个包含服务器资源的Response对象。

  - 完整方法：

    `request.get(url, params=None, **kwargs)`

    url: 拟获取页面的url链接。

    params: url中的额外参数，字典or字节流格式，可选。

    **kwargs: 12个控制访问的参数

  - 其实requests只有一个request方法，其它6个方法都通过调用request方法实现

  - Response对象：包含爬虫返回的全部内容。

    ```
    import requests
    r = requests.get(url)
    print(r.status_code) #200
    type(r) #<class 'requests.model.Response'>
    r.headers #获得页面的头部信息...
    ```

  - Response对象的属性：

  | 属性                  | 说明                            |
  | ------------------- | ----------------------------- |
  | r.status_code       | HTTP请求的返回状态，200表示连接成功，404表示失败 |
  | r.text              | HTTP响应内容的字符串样式，即：url对应的页面的内容  |
  | r.encoding          | 从HTTP header中猜测的响应内容编码方式      |
  | r.apparent_encoding | 从内容中分析出的响应内容编码方式（备选编码方式）      |
  | r.content           | HTTP响应内容的二进制形式                |

  ​

    -  流程：

       Response的对象 —> r.status_code — —> 200 — r.text, r.encoding, r.apparent_encoding, r.content

  ​				     				   —>404或其他 — 某些原因出错，将产生异常

  - 理解Response的编码：

    | 属性                  | 说明                                       |
    | ------------------- | ---------------------------------------- |
    | r.encoding          | 从HTTP header中猜测的响应内容编码方式(从charset字段获得，如果header中不存在charset字段，则认为编码为ISO-8859-1) |
    | r.apparent_encoding | 从内容中分析出的响应内容编码方式（根据内容分析出的编码方式，比encoding更加准确） |



### Unit 2: 爬取网页的通用代码框架

- 网络连接有风险
- 异常处理很重要

1. 理解Requests库的异常

   | 异常                        | 说明                      |
   | ------------------------- | ----------------------- |
   | requests.ConnectionError  | 网络连接错误，如DNS查询失败，拒绝连接等   |
   | requests.HTTPError        | HTTP错误                  |
   | requests.URLRequired      | URL缺失                   |
   | requests.TooManyRedirects | 超过最大重定向次数（对一些复杂链接进行访问时） |
   | requests.ConnectTimeout   | 连接远程服务器超时               |
   | requests.Timeout          | 请求URL超时（发出请求到收到内容的整个过程） |

   - `r.raise_for_status()`方法：判断返回类型，如果不是200，就产生requests.HTTPError。

     ​

2. 一个通用代码框架

   ```
   import requests

   def getHTMLText(url):
   	try:
   		r = requests.get(url, timeout=30)
   		r.raise_for_status() #如果状态不是200，引发requests.HTTPError异常
   		r.encoding = r.apparent_encoding
   		return r.text
   	except:
   		return "产生异常"

   if __name__ == "__main__":
   	url = "http://www.baidu.com"
   	print(getHTMLText(url))
   ```

   ​

### Unit 3: HTTP协议及Requests库方法

1. Requests库的七个方法
2. HTTP协议   

- HTTP，Hypertext Transfer Protocol，超文本传输协议。   

  HTTP是一个基于“请求与响应”模式的，无状态的应用层协议。  

  采用URL作为定位网络资源的标识。   

  URL格式： `http://host[:port][path]`

- HTTP URL的理解：   

  URL是通过HTTP协议存取资源的Internet路径，一个URL对应一个数据资源。  

- HTTP协议对资源的操作

  | 方法     | 说明                             |
  | ------ | ------------------------------ |
  | GET    | 请求获取URL位置的资源                   |
  | HEAD   | 请求获取URL位置资源的响应消息报告，即获得该资源的头部信息 |
  | POST   | 请求向URL位置的资源后附加新的数据             |
  | PUT    | 请求向URL位置存储一个资源，覆盖原URL位置的资源     |
  | PATCH  | 请求局部更新URL位置的资源，即改变该处资源的部分内容    |
  | DELETE | 请求删除URL位置存储的资源                 |

  - 通过URL对资源定位
  - 通过这6个常用方法对资源进行管理
  - 每一次操作都是独立无状态的
  - 在HTTP协议的世界里，网络通道和服务器都是黑盒子，能看到的就是URL链接及对其的相关操作。

- PATCH比PUT更节省带宽（修改局部，不必提交整个）。

3. HTTP协议与Requests库  

- 方法的功能是一致的。

- Requests库的方法：

  - head()方法：获取资源的概要信息，节省流量。

  - post()方法：向URL POST一个dict，自动编码为表单（键值对被放到form字段下）。

    POST一个字符串，自动编码为data，被放入data字段下。

    ```
    >>> payload = {'key1': 'value1', 'key2': 'value2'}
    >>> r = requests.post(url, data = patload)
    >>> print(r.text)
    {    ...
    	"form": {
          'key2': 'value2',
          'key1': 'value1'
    	},  
    }
    # post方法根据用户提交内容，在服务器上做相关整理
    ```

  - put()方法：与post方法类似，但是会把原有内容覆盖掉。

4. Requests七个主要方法的解析

- request方法  `requests.request(method, url, **kwargs)`

  - method：请求方法，有：  

    GET, HEAD, POST, PUT, PATCH, DELETE, OPTIONS(不与获取资源直接相关) 

  - **kwargs：控制访问的参数，均为可选项  （前4个要灵活掌握）。

    1. params: 字典or字节序列，作为参数增加到url中。

    ```
    >>> kv = {'k1': 'v1', 'k2': 'v2'}
    >>> r = requests.request('GET', 'http://xxx/yy', params=kv)
    >>> print(r.url)
    http://xxx/yy?k1=v1&k2=v2
    ```

    2. data: 字典，字节序列或文件对象，作为Request的内容。	

    ```
    >>> kv = {'k1': 'v1', 'k2': 'v2'}
    >>> r = requests.request('POST', 'http://xxx/yy', data=kv)
    >>> body = '主体内容'
    >>> r = requests.request('POST', 'http://xxx/yy', data=body)
    ```

    3. json:  JSON格式的数据，作为Request的内容。

       ```
       >>> kv = {'k1': 'v1'}
       >>> r = requests.request('POST', 'http://xxx/yy', json=kv)
       ```

    4. headers: 字典，HTTP定制头。

       ```
       >>> hd = {'user-agent': 'Chrome/10'}
       >>> r = requests.request('POST', 'http://xxx/yy', headers=hd)
       ```

    5. cookies: 字典或CookieJar，Request中的cookie。

    6. auth: 元祖，支持HTTP认证功能。

    7. files：字典类型，传输文件。

       ```
       >>> fs = {'file': open('data.xls', 'rb')}
       >>> r = requests.request('POST', 'http://xxx/yy', files=fs)
       ```

    8. timeout：设定超时时间，单位为秒。

    9. proxies：字典类型，设定访问代理服务器，可以增加登录认证。

       ```
       >>> pxs = {'http': 'http://user:pass@10.10.10,1:1234',
       		   'https': 'https://10.10.10.1.4321'}
       >>> r = requests.request('POST', 'http://xxx/yy', proxies=pxs)
       ```

    10. allow_redirects: True/False，默认为True，重定向开关。

    11. stream：True/False， 默认为True，获取内容立即下载开关。

    12. verify：True/False，默认为True，认证SSL证书开关。

    13. cert：本地SSl证书路径。

- `requests.get(url, params=None, **kwargs)`

  - url：拟获取的页面的url链接。
  - params：url中的额外参数。
  - **kwargs：上面除params外的12个控制访问参数。

- `requests.head(url, **kwargs)`

  - **kwargs：13个控制访问参数。

- `requests.post(url, data=None, json=None,  **kwargs)`

- `requests.put(url, data=None,  **kwargs)`

- `requests.patch(url, data=None,  **kwargs)`

- `requests.delete(url,  **kwargs)`

- 事实上后六个为request方法的封装，其中get方法最常用。

### 小结

- requests七个方法：request，get，head，post，put，patch，delete

- 因为网络安全限制，我们很难向一个url发起post，put，patch，delete请求。

- 最常用的就是get，大型链接可用head获取概要。(爬虫主要用这两个)

- 通用代码框架：try-except。（保证异常得到有效处理）

  ```
  def getHTMLText(url):
  	try:
  		r = requests.get(url, timeout=30)
  		r.raise_for_status() #如果状态不是200，引发requests.HTTPError异常
  		r.encoding = r.apparent_encoding
  		return r.text
  	except:
  		return "产生异常"
  ```

  ​